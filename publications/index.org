# Created 2022-06-28 Tue 13:12
#+options: H:8
#+title: Publications
#+description: Aviral's Publications
#+include-header: false
#+include-footer: false
#+html_head_extra: <link rel="stylesheet" type="text/css" href="/static/css/publications.css" />
#+tags: papers








- [[https://2021.splashcon.org/track/splash-2021-oopsla][*OOPSLA'21*]] :: *Promises Are Made to Be Broken* \\
     _Aviral Goel_, Jan Ječmen, Olivier Flückiger, Sebástian Krynski, Jan Vitek


     ABSTRACT
     [[file:static/pdfs/promises-are-made-to-be-broken.pdf][⸢PAPER⸥]]
     [[https://doi.org/10.5281/zenodo.5394235][⸢SOFTWARE⸥]]
     [[https://youtu.be/8L_a7mhYdyM][⸢TALK⸥]]
     [[https://doi.org/10.1145/3485478][⸢DOI:10.1145/3485478⸥]]


         Function calls in the R language do not evaluate their arguments, these are
         passed to the callee as suspended computations and evaluated if needed. After 25
         years of experience with the language, there are very few cases where
         programmers leverage delayed evaluation intentionally and laziness comes at a
         price in performance and complexity. This paper explores how to evolve the
         semantics of a lazy language towards strictness-by-default and
         laziness-on-demand. To provide a migration path, it is necessary to provide
         tooling for developers to migrate libraries without introducing errors. This
         paper reports on a dynamic analysis that infers strictness signatures for
         functions to capture both intentional and accidental laziness. Over 99% of the
         inferred signatures were correct when tested against clients of the libraries.

-----

- [[https://2021.splashcon.org/track/splash-2021-oopsla][*OOPSLA'21*]] :: *What We Eval in the Shadows* \\
      _Aviral Goel_, Pierre Donat-Bouillud, Filip Křikava, Christoph M. Kirsch, Jan Vitek
 
 
      ABSTRACT
      [[file:static/pdfs/what-we-eval-in-the-shadows.pdf][⸢PAPER⸥]]
      [[https://doi.org/10.5281/zenodo.5415230][⸢SOFTWARE⸥]]
      [[https://youtu.be/aEPd8ijSHuI][⸢TALK⸥]]
      [[https://doi.org/10.1145/3485502][⸢DOI:10.1145/3485502⸥]]
 
     
          Most dynamic languages allow users to turn text into code using various
          functions, often named =eval=, with language-dependent semantics. The widespread
          use of these reflective functions hinders static analysis and prevents compilers
          from performing optimizations. This paper aims to provide a better sense of why
          programmers use =eval=. Understanding why =eval= is used in practice is key to
          finding ways to mitigate its negative impact. We have reasons to believe that
          reflective feature usage is language and application domains specific; we focus
          on data science code written in R and compare our results to previous work that
          analyzed web programming in JavaScript. We analyze 49,296,059 calls to =eval= from
          240,327 scripts extracted from 15,401 R packages. We find that =eval= is indeed in
          widespread use; R’s =eval= is more pervasive and arguably dangerous than what was
          previously reported for JavaScript.

-----

- [[https://conf.researchr.org/home/dls-2021][*DLS'21*]] :: *First-Class Environments in R* \\
      _Aviral Goel_, Jan Vitek
 
 
      ABSTRACT
      [[file:static/pdfs/first-class-environments-in-r.pdf][⸢PAPER⸥]]     
      [[https://doi.org/10.1145/3486602.3486768][⸢DOI:10.1145/3486602.3486768⸥]]
 
     
          The R programming language is widely used for statistical computing. To enable
          interactive data exploration and rapid prototyping, R encourages a dynamic
          programming style. This programming style is supported by features such as
          first-class environments. Amongst widely used languages, R has the richest
          interface for programmatically manipulating environments. With the flexibility
          afforded by reflective operations on first-class environments, come significant
          challenges for reasoning and optimizing user-defined code. This paper documents
          the reflective interface used to operate over first-class environment. We
          explain the rationale behind its design and conduct a large-scale study of how
          the interface is used in popular libraries



- [[https://2020.splashcon.org/track/splash-2020-oopsla][*OOPSLA'20*]] :: *Designing Types for R, Empirically* \\
     Alexi Turcotte, _Aviral Goel_, Filip Křikava, Jan Vitek


     ABSTRACT
     [[file:static/pdfs/designing-types-for-r-empirically.pdf][⸢PAPER⸥]]
     [[https://zenodo.org/record/4037278#.X9U4B1OYUUF][⸢SOFTWARE⸥]]
     [[https://youtu.be/GMrLtYg0VGA][⸢TALK⸥]]
     [[https://doi.org/10.1145/3428249][⸢DOI:10.1145/3428249⸥]]   

    
         The R programming language is widely used in a variety of domains. It was
         designed to favor an interactive style of programming with minimal syntactic and
         conceptual overhead. This design is well suited to data analysis, but a bad fit
         for tools such as compilers or program analyzers. In particular, R has no type
         annotations, and all operations are dynamically checked at runtime. The starting
         point for our work are the two questions: /what expressive power is needed to
         accurately type R code?/ and /which type system is the R community willing to
         adopt/? Both questions are difficult to answer without actually experimenting
         with a type system. The goal of this paper is to provide data that can feed into
         that design process. To this end, we perform a large corpus analysis to gain
         insights in the degree of polymorphism exhibited by idiomatic R code and explore
         potential benefits that the R community could accrue from a simple type system.
         As a starting point, we infer type signatures for 25,215 functions from 412
         packages among the most widely used open source R libraries. We then conduct an
         evaluation on 8,694 clients of these packages, as well as on end-user code from
         the Kaggle data science competition website.



- [[https://2019.splashcon.org/track/splash-2019-oopsla][*OOPSLA'19*]] :: *On the Design, Implementation, and Use of Laziness in R* \\
     _Aviral Goel_, Jan Vitek


     ABSTRACT
     [[file:static/pdfs/on-the-design-implementation-and-use-of-laziness-in-r.pdf][⸢PAPER⸥]]
     [[https://zenodo.org/record/3369573#.XaC2c-aYVhE][⸢SOFTWARE⸥]]
     [[https://youtu.be/qLxz9HPP6wI][⸢TALK⸥]]
     [[https://doi.org/10.1145/3360579][⸢DOI:10.1145/3360579⸥]]   

    
         The R programming language has been lazy for over twenty-five years. This paper
         presents a review of the design and implementation of call-by-need in R, and a
         data-driven study of how generations of programmers have put laziness to use in
         their code. We analyze 16,707 packages and observe the creation of 270.9 B
         promises. Our data suggests that there is little supporting evidence to assert
         that programmers use laziness to avoid unnecessary computation or to operate
         over infinite data structures. For the most part R code appears to have been
         written without reliance on, and in many cases even knowledge of, delayed
         argument evaluation. The only significant exception is a small number of
         packages which leverage call-by-need for meta-programming.



- [[https://popl18.sigplan.org/][*POPL'18*]] :: *Correctness of Speculative Optimizations with Dynamic Deoptimization* \\
     Olivier Flückiger, Gabriel Scherer, Ming-ho Yee, _Aviral Goel_, Amal Ahmed, Jan Vitek


     ABSTRACT
     [[file:static/pdfs/correctness-of-speculative-optimizations-with-dynamic-deoptimization.pdf][⸢PAPER⸥]]
     [[https://doi.org/10.1145/3158137][⸢DOI:10.1145/3158137⸥]]   

    
         High-performance dynamic language implementations make heavy use of speculative
         optimizations to achieve speeds close to statically compiled languages. These
         optimizations are typically performed by a just-in-time compiler that generates
         code under a set of assumptions about the state of the program and its
         environment. In certain cases, a program may execute code compiled under
         assumptions that are no longer valid. The implementation must then deoptimize
         the program on-the-fly; this entails finding semantically equivalent code that
         does not rely on invalid assumptions, translating program state to that expected
         by the target code, and transferring control. This paper looks at the
         interaction between optimization and deoptimization, and shows that reasoning
         about speculation is surprisingly easy when assumptions are made explicit in the
         program representation. This insight is demonstrated on a compiler intermediate
         representation, named =sourir=, modeled after the high-level representation for a
         dynamic language. Traditional compiler optimizations such as constant folding,
         unreachable code elimination, and function inlining are shown to be correct in
         the presence of assumptions. Furthermore, the paper establishes the correctness
         of compiler transformations specific to deoptimization: namely unrestricted
         deoptimization, predicate hoisting, and assume composition.
